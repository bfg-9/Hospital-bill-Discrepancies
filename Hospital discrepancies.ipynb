{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objective 1: Investigate Severity and Treatment Outcomes\n",
        "We'll use a Random Forest Regressor for predicting treatment outcomes based on the severity of illness and other relevant features.\n",
        "\n",
        "# Objective 2: Systematic Differences in Billing Errors\n",
        "We'll use a Random Forest Classifier to identify systematic differences in billing errors based on payment type and other features.\n",
        "\n",
        "# Objective 3: Patterns of Billing Disparities\n",
        "We'll use a Gradient Boosting Regressor to predict billing amounts for different insurance types."
      ],
      "metadata": {
        "id": "1K1VyGRc1Bjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install SHAP(Shapely Additive exPlanations)"
      ],
      "metadata": {
        "id": "oABL4vztJLcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "bV2UP6NZGh9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install LIME (Local Interpretable Model-agnostic Explanations)"
      ],
      "metadata": {
        "id": "n8wBaQK7JdVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lime"
      ],
      "metadata": {
        "id": "94Gk7vraGzK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install ELI5"
      ],
      "metadata": {
        "id": "Ef1SSSYkJqLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eli5"
      ],
      "metadata": {
        "id": "NgJ3n0qkHZ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "USseB8j0Jq2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Tensorflow"
      ],
      "metadata": {
        "id": "69PQ-XWTJ3ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "tN8CnQIeIkwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the necessary Libraries"
      ],
      "metadata": {
        "id": "h0-XIIpTJ_QB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noSqq4CfxaZV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "import shap\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import seaborn as sns\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "4mCii1dnKGnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "5LRSrPbZzinI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "RcrLUARm2DoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "#file_path = '/mnt/data/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(data.describe(include='all'))\n",
        "\n",
        "# Data types and missing values\n",
        "print(\"\\nData types and missing values:\")\n",
        "print(data.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values count:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Visualize missing values\n",
        "msno.matrix(data)\n",
        "plt.show()\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_features = data.select_dtypes(include=[object]).columns\n",
        "encoder = LabelEncoder()\n",
        "for feature in categorical_features:\n",
        "    data[feature] = encoder.fit_transform(data[feature].astype(str))\n",
        "\n",
        "# Distribution of numerical features\n",
        "numerical_features = data.select_dtypes(include=[np.number]).columns\n",
        "print(\"\\nNumerical features:\")\n",
        "print(numerical_features)\n",
        "\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data[feature].dropna(), kde=True)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "# Distribution of categorical features\n",
        "print(\"\\nCategorical features:\")\n",
        "print(categorical_features)\n",
        "\n",
        "for feature in categorical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(y=data[feature], order=data[feature].value_counts().index)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel('Count')\n",
        "    plt.ylabel(feature)\n",
        "    plt.show()\n",
        "\n",
        "# Correlation matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr_matrix = data.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Pairplot for numerical features\n",
        "sns.pairplot(data[numerical_features])\n",
        "plt.show()\n",
        "\n",
        "# Box plots to detect outliers\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x=data[feature])\n",
        "    plt.title(f'Box plot of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.show()\n",
        "\n",
        "# Relationship between numerical features and target variable (example: Total Charges)\n",
        "target = 'Total Charges'\n",
        "for feature in numerical_features:\n",
        "    if feature != target:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(x=data[feature], y=data[target])\n",
        "        plt.title(f'Relationship between {feature} and {target}')\n",
        "        plt.xlabel(feature)\n",
        "        plt.ylabel(target)\n",
        "        plt.show()\n",
        "\n",
        "# Distribution of target variable (example: Total Charges)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data[target].dropna(), kde=True)\n",
        "plt.title(f'Distribution of {target}')\n",
        "plt.xlabel(target)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Checking relationships in categorical features with target variable\n",
        "for feature in categorical_features:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.boxplot(x=data[feature], y=data[target])\n",
        "    plt.title(f'Relationship between {feature} and {target}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel(target)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "vJLN8ATK7H5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "XB8rw0amKJOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])"
      ],
      "metadata": {
        "id": "Gv28Q4AmzikU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Billing Discrepancy column"
      ],
      "metadata": {
        "id": "jbkUEi2HKQfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']"
      ],
      "metadata": {
        "id": "dAH4i1suzihz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective 1: Predicting Treatment Outcomes\n",
        "# Features and target"
      ],
      "metadata": {
        "id": "BhTIXivaKTYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_obj1 = ['APR Severity of Illness Code', 'Length of Stay', 'Total Charges']\n",
        "X1 = cleaned_data[features_obj1]\n",
        "y1 = cleaned_data['Total Costs']\n"
      ],
      "metadata": {
        "id": "9eXTtauhzifI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "syf7LDpfKW1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "A1tv-2-Fzicd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardize features"
      ],
      "metadata": {
        "id": "tKrLkX9aKZvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "X1_train_scaled = scaler.fit_transform(X1_train)\n",
        "X1_test_scaled = scaler.transform(X1_test)\n"
      ],
      "metadata": {
        "id": "mC1itsgGziZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Random Forest Regressor"
      ],
      "metadata": {
        "id": "oYosyFPdKfvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X1_train_scaled, y1_train)\n"
      ],
      "metadata": {
        "id": "xEg6OR9NziW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate using RFR\n",
        "\n"
      ],
      "metadata": {
        "id": "LTCPGXqfKlGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_pred = rf_regressor.predict(X1_test_scaled)\n",
        "mse_obj1 = mean_squared_error(y1_test, y1_pred)\n",
        "print(f'Objective 1 - Mean Squared Error: {mse_obj1}')\n"
      ],
      "metadata": {
        "id": "KEUlhYaFziUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate its accuracy and precision of RFR"
      ],
      "metadata": {
        "id": "IQ1xzKXXK6UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thereby reaching with a **84% accuracy** using RFR\n",
        "Objective 1 - Mean Squared Error: 5176.0114566283455\n",
        "Objective 1 - Mean Absolute Error: 42.13125000000002\n",
        "Objective 1 - Mean Absolute Percentage Error: 3.1584146341718866\n",
        "Objective 1 - Root Mean Squared Error: 71.94450261575477\n",
        "Objective 1 - **R^2 Score: 0.8479155196583776**\n"
      ],
      "metadata": {
        "id": "-k6IP1LcLHLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_pred = rf_regressor.predict(X1_test_scaled)\n",
        "mse_obj1 = mean_squared_error(y1_test, y1_pred)\n",
        "mae_obj1 = mean_absolute_error(y1_test, y1_pred)\n",
        "mape_obj1 = mean_absolute_percentage_error(y1_test, y1_pred)\n",
        "rmse_obj1 = np.sqrt(mse_obj1)\n",
        "r2_obj1 = r2_score(y1_test, y1_pred)\n",
        "\n",
        "\n",
        "print(f'Objective 1 - Mean Squared Error: {mse_obj1}')\n",
        "print(f'Objective 1 - Mean Absolute Error: {mae_obj1}')\n",
        "print(f'Objective 1 - Mean Absolute Percentage Error: {mape_obj1}')\n",
        "print(f'Objective 1 - Root Mean Squared Error: {rmse_obj1}')\n",
        "print(f'Objective 1 - R^2 Score: {r2_obj1}')"
      ],
      "metadata": {
        "id": "kbgXV-XnBOmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# SHAP Analysis for Objective 1"
      ],
      "metadata": {
        "id": "V2eaYvbM4SSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer_rf = shap.TreeExplainer(rf_regressor)\n",
        "shap_values_rf = explainer_rf.shap_values(X1_test_scaled)"
      ],
      "metadata": {
        "id": "8PGrLU2n3WFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SHAP summary plot for Objective 1\")\n",
        "shap.summary_plot(shap_values_rf, X1_test)"
      ],
      "metadata": {
        "id": "zMxArZDU2y5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # LIME Analysis for Objective 1"
      ],
      "metadata": {
        "id": "sJ7CdJLj81pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X1_train_scaled,\n",
        "    feature_names=features_obj1,\n",
        "    class_names=['Total Costs'],\n",
        "    verbose=True,\n",
        "    mode='regression'\n",
        ")"
      ],
      "metadata": {
        "id": "a3jnTbPt81L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explain a single instance"
      ],
      "metadata": {
        "id": "JhlB96zvL1nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i = 0  # Index of the instance to explain\n",
        "lime_exp = lime_explainer.explain_instance(X1_test_scaled[i], rf_regressor.predict)"
      ],
      "metadata": {
        "id": "1bcerSD68-AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showing the explanation after implementing LIME"
      ],
      "metadata": {
        "id": "OLJFt9pfL9sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"LIME explanation for a single instance\")\n",
        "lime_exp.show_in_notebook(show_table=True, show_all=False)"
      ],
      "metadata": {
        "id": "5os789ak898A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the explanation as a plot"
      ],
      "metadata": {
        "id": "-rF7zPRRMXG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lime_exp.as_pyplot_figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2p_VqUn0895Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELI 5 obj1"
      ],
      "metadata": {
        "id": "iJuK2IU-EJp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementing ELI5 for\n",
        "\n",
        "1.   Text Explanation\n",
        "2.   Explanation for single prediction\n",
        "3.   Also understanding the Permutation Importance\n",
        "\n"
      ],
      "metadata": {
        "id": "e47k_k9iN0sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ELI5 Text Explanation\n",
        "print(eli5.format_as_text(eli5.explain_weights(rf_regressor, feature_names=features_obj1)))\n",
        "\n",
        "# ELI5 HTML Explanation for Jupyter Notebook\n",
        "\n",
        "display(eli5.show_weights(rf_regressor, feature_names=features_obj1))\n",
        "\n",
        "# ELI5 Explanation for a Single Prediction\n",
        "i = 0  # Index of the instance to explain\n",
        "print(eli5.format_as_text(eli5.explain_prediction(rf_regressor, X1_test_scaled[i], feature_names=features_obj1)))\n",
        "display(eli5.show_prediction(rf_regressor, X1_test_scaled[i], feature_names=features_obj1))\n",
        "\n",
        "# Permutation Importance\n",
        "perm = PermutationImportance(rf_regressor, random_state=42).fit(X1_test_scaled, y1_test)\n",
        "display(eli5.show_weights(perm, feature_names=features_obj1))"
      ],
      "metadata": {
        "id": "HgjkXyoIEJZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective 2: Identifying Systematic Billing Errors"
      ],
      "metadata": {
        "id": "gfI_AuMzPyGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Features and target"
      ],
      "metadata": {
        "id": "R6H2lzMgP2X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n"
      ],
      "metadata": {
        "id": "GvR82Da0ziQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Encode categorical features"
      ],
      "metadata": {
        "id": "JyuVw9niP7kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n"
      ],
      "metadata": {
        "id": "7KmTiVS4ziNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Split data"
      ],
      "metadata": {
        "id": "EYUDSXiuQFVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UA2eHgpjziLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Random Forest Classifier for objective 2"
      ],
      "metadata": {
        "id": "gQEHH48GQJja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X2_train, y2_train)\n"
      ],
      "metadata": {
        "id": "y3RoOj_P0VNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate RFC\n",
        "\n",
        "\n",
        "*   Accuracy: 0.9166666666666666\n",
        "\n"
      ],
      "metadata": {
        "id": "uuZlKPvuQPwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y2_pred = rf_classifier.predict(X2_test)\n",
        "accuracy_obj2 = accuracy_score(y2_test, y2_pred)\n",
        "print(f'Objective 2 - Accuracy: {accuracy_obj2}')\n",
        "print(classification_report(y2_test, y2_pred))\n"
      ],
      "metadata": {
        "id": "FAgqEXqt0VLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP Analysis for Objective 2"
      ],
      "metadata": {
        "id": "UY4F9TPjNRji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "explainer_rf_classifier = shap.TreeExplainer(rf_classifier)\n",
        "shap_values_rf_classifier = explainer_rf_classifier.shap_values(X2_test)"
      ],
      "metadata": {
        "id": "Th4i7VJ94ulG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP summary plot for Objective 2"
      ],
      "metadata": {
        "id": "WXSOfEtwNaIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SHAP summary plot for Objective 2\")\n",
        "shap.summary_plot(shap_values_rf_classifier, X2_test)"
      ],
      "metadata": {
        "id": "D0BUGYWs4ucC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y2_pred = rf_classifier.predict(X2_test)\n",
        "accuracy_obj2 = accuracy_score(y2_test, y2_pred)\n",
        "precision_obj2 = precision_score(y2_test, y2_pred)\n",
        "recall_obj2 = recall_score(y2_test, y2_pred)\n",
        "f1_obj2 = f1_score(y2_test, y2_pred)\n",
        "conf_matrix_obj2 = confusion_matrix(y2_test, y2_pred)\n",
        "\n",
        "print(f'Objective 2 - Accuracy: {accuracy_obj2}')\n",
        "print(f'Objective 2 - Precision: {precision_obj2}')\n",
        "print(f'Objective 2 - Recall: {recall_obj2}')\n",
        "print(f'Objective 2 - F1 Score: {f1_obj2}')\n",
        "print(f'Objective 2 - Confusion Matrix:\\n{conf_matrix_obj2}')\n",
        "print(classification_report(y2_test, y2_pred))\n"
      ],
      "metadata": {
        "id": "cgymYmXDATeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIME Analysis for Objective 2"
      ],
      "metadata": {
        "id": "It0YZqTqQ6vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "X2_np = X2.values\n",
        "y2_np = y2.values\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_np, y2_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X2_train, y2_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred = rf_classifier.predict(X2_test)\n",
        "accuracy_obj2 = accuracy_score(y2_test, y2_pred)\n",
        "print(f'Objective 2 - Accuracy: {accuracy_obj2}')\n",
        "print(classification_report(y2_test, y2_pred))\n",
        "\n",
        "# LIME Analysis for Objective 2\n",
        "lime_explainer_obj2 = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X2_train,\n",
        "    feature_names=features_obj2,\n",
        "    class_names=['No Billing Error', 'Billing Error'],\n",
        "    categorical_features=[3],  # Specify the index of categorical features in the numpy array\n",
        "    verbose=True,\n",
        "    mode='classification'\n",
        ")"
      ],
      "metadata": {
        "id": "wThz9qQ89pMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explain a single instance"
      ],
      "metadata": {
        "id": "9dYgPn3HQ_lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i = 0  # Index of the instance to explain\n",
        "lime_exp_obj2 = lime_explainer_obj2.explain_instance(X2_test[i], rf_classifier.predict_proba)\n",
        "\n",
        "# Show the explanation\n",
        "print(\"LIME explanation for a single instance\")\n",
        "lime_exp_obj2.show_in_notebook(show_table=True, show_all=False)"
      ],
      "metadata": {
        "id": "DA9s3Se_9pIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the explanation using LIME as a plot for objective 2"
      ],
      "metadata": {
        "id": "OXBakB4eRC9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lime_exp_obj2.as_pyplot_figure()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4aSwkaR_9pDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELI5"
      ],
      "metadata": {
        "id": "AiwKdvBZDb8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELI5 Text Explanation"
      ],
      "metadata": {
        "id": "wjYuaYM4RTzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(eli5.format_as_text(eli5.explain_weights(rf_classifier, feature_names=features_obj2)))\n",
        "\n",
        "# ELI5 HTML Explanation for Jupyter Notebook\n",
        "display(eli5.show_weights(rf_classifier, feature_names=features_obj2))\n",
        "\n",
        "# ELI5 Explanation for a Single Prediction\n",
        "i = 0  # Index of the instance to explain\n",
        "print(eli5.format_as_text(eli5.explain_prediction(rf_classifier, X2_test[i], feature_names=features_obj2)))\n",
        "display(eli5.show_prediction(rf_classifier, X2_test[i], feature_names=features_obj2))\n",
        "\n",
        "# Permutation Importance\n",
        "perm = PermutationImportance(rf_classifier, random_state=42).fit(X2_test, y2_test)\n",
        "display(eli5.show_weights(perm, feature_names=features_obj2))\n"
      ],
      "metadata": {
        "id": "-draLEqb9pAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective 3: Predicting Billing Amounts for Different Insurance Types\n",
        "\n",
        "\n",
        "*   Features and target\n",
        "\n"
      ],
      "metadata": {
        "id": "dR4mxOgQRxai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_obj3 = ['APR Severity of Illness Code', 'Payment Typology 1', 'CCS Procedure Code']\n",
        "X3 = cleaned_data[features_obj3]\n",
        "y3 = cleaned_data['Total Charges']"
      ],
      "metadata": {
        "id": "iL1TzCll0VI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical features\n",
        "X3['Payment Typology 1'] = encoder.fit_transform(X3['Payment Typology 1'])\n",
        "X3['CCS Procedure Code'] = cleaned_data['CCS Procedure Code'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "l8v9IEww0VGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "1mLtYxEsSFwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZZtDtPlR0VEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Gradient Boosting Regressor"
      ],
      "metadata": {
        "id": "jVF4gZGkSKSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_regressor.fit(X3_train, y3_train)\n"
      ],
      "metadata": {
        "id": "NXdYig8p0VBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate"
      ],
      "metadata": {
        "id": "Acj_OpC9SO0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y3_pred = gb_regressor.predict(X3_test)\n",
        "mse_obj3 = mean_squared_error(y3_test, y3_pred)\n",
        "print(f'Objective 3 - Mean Squared Error: {mse_obj3}')"
      ],
      "metadata": {
        "id": "PxpznGeh0U_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP Analysis for Objective 3"
      ],
      "metadata": {
        "id": "T6iwqOqhSQ3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "explainer_gb = shap.TreeExplainer(gb_regressor)\n",
        "shap_values_gb = explainer_gb.shap_values(X3_test)"
      ],
      "metadata": {
        "id": "a7KoMEl25Byw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SHAP summary plot for Objective 3\")\n",
        "shap.summary_plot(shap_values_gb, X3_test)"
      ],
      "metadata": {
        "id": "vi1XxOVQ5BwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependence Plot\n",
        "print(\"SHAP dependence plot for 'Total Charges'\")\n",
        "shap.dependence_plot('Total Charges', shap_values_rf, X1_test)"
      ],
      "metadata": {
        "id": "CPFYjpA77Otn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Force Plot for a single instance\n",
        "print(\"SHAP force plot for a single instance\")\n",
        "shap.force_plot(explainer_rf.expected_value, shap_values_rf[0], X1_test.iloc[0])"
      ],
      "metadata": {
        "id": "tr5ciw3N7Oq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Waterfall Plot for a single instance"
      ],
      "metadata": {
        "id": "jEoYEsSSSfl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"SHAP waterfall plot for a single instance\")\n",
        "shap.waterfall_plot(shap.Explanation(values=shap_values_rf[0],\n",
        "                                     base_values=explainer_rf.expected_value,\n",
        "                                     data=X1_test.iloc[0]))\n"
      ],
      "metadata": {
        "id": "3IM-loOS7OoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar Plot\n",
        "\n",
        "*   SHAP bar plot for Objective 1\n",
        "\n"
      ],
      "metadata": {
        "id": "FTf7Ups5SsG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"SHAP bar plot for Objective 1\")\n",
        "shap.summary_plot(shap_values_rf, X1_test, plot_type=\"bar\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "31F0-rBz7tBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lime Objective 3"
      ],
      "metadata": {
        "id": "kItWQglW_7fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "X3_np = X3.values\n",
        "y3_np = y3.values\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_np, y3_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regressor\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_regressor.fit(X3_train, y3_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred = gb_regressor.predict(X3_test)\n",
        "mse_obj3 = mean_squared_error(y3_test, y3_pred)\n",
        "print(f'Objective 3 - Mean Squared Error: {mse_obj3}')\n",
        "\n",
        "# LIME Analysis for Objective 3\n",
        "lime_explainer_obj3 = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X3_train,\n",
        "    feature_names=features_obj3,\n",
        "    class_names=['Total Charges'],\n",
        "    categorical_features=[1, 2],  # Specify the indices of categorical features in the numpy array\n",
        "    verbose=True,\n",
        "    mode='regression'\n",
        ")\n",
        "\n",
        "# Explain a single instance\n",
        "i = 0  # Index of the instance to explain\n",
        "lime_exp_obj3 = lime_explainer_obj3.explain_instance(X3_test[i], gb_regressor.predict)\n",
        "\n",
        "# Show the explanation\n",
        "print(\"LIME explanation for a single instance\")\n",
        "lime_exp_obj3.show_in_notebook(show_table=True, show_all=False)\n",
        "\n",
        "# Show the explanation as a plot\n",
        "lime_exp_obj3.as_pyplot_figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ahj8VGtx_6-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELI 5 for obj3\n"
      ],
      "metadata": {
        "id": "vqcIM_WiEl2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ELI5 Text Explanation\n",
        "print(eli5.format_as_text(eli5.explain_weights(gb_regressor, feature_names=features_obj3)))\n",
        "\n",
        "# ELI5 HTML Explanation for Jupyter Notebook\n",
        "display(eli5.show_weights(gb_regressor, feature_names=features_obj3))\n",
        "\n",
        "# ELI5 Explanation for a Single Prediction\n",
        "i = 0  # Index of the instance to explain\n",
        "print(eli5.format_as_text(eli5.explain_prediction(gb_regressor, X3_test[i], feature_names=features_obj3)))\n",
        "display(eli5.show_prediction(gb_regressor, X3_test[i], feature_names=features_obj3))\n",
        "\n",
        "# Permutation Importance\n",
        "perm = PermutationImportance(gb_regressor, random_state=42).fit(X3_test, y3_test)\n",
        "display(eli5.show_weights(perm, feature_names=features_obj3))"
      ],
      "metadata": {
        "id": "a7jxYqycEfu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate GBR (R^2 Score: 0.26861310772369096)\n",
        "\n",
        "\n",
        "1.   Objective 3 - Mean Squared Error: 34945.09096476254\n",
        "2.   Objective 3 - Mean Absolute Error: 134.2881684673238\n",
        "3.   Objective 3 - Mean Absolute Percentage Error: 0.939080397251264\n",
        "4.   Objective 3 - Root Mean Squared Error: 186.93606116734819\n",
        "5.   Objective 3 - R^2 Score: 0.26861310772369096\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOKKBa1kTIQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y3_pred = gb_regressor.predict(X3_test)\n",
        "mse_obj3 = mean_squared_error(y3_test, y3_pred)\n",
        "mae_obj3 = mean_absolute_error(y3_test, y3_pred)\n",
        "mape_obj3 = mean_absolute_percentage_error(y3_test, y3_pred)\n",
        "rmse_obj3 = np.sqrt(mse_obj3)\n",
        "r2_obj3 = r2_score(y3_test, y3_pred)\n",
        "\n",
        "print(f'Objective 3 - Mean Squared Error: {mse_obj3}')\n",
        "print(f'Objective 3 - Mean Absolute Error: {mae_obj3}')\n",
        "print(f'Objective 3 - Mean Absolute Percentage Error: {mape_obj3}')\n",
        "print(f'Objective 3 - Root Mean Squared Error: {rmse_obj3}')\n",
        "print(f'Objective 3 - R^2 Score: {r2_obj3}')"
      ],
      "metadata": {
        "id": "roLCUEtd_650"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Objective 3: Predicting Billing Amounts for Different Insurance Types\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 3\n",
        "features_obj3 = ['APR Severity of Illness Code', 'Payment Typology 1', 'CCS Procedure Code']\n",
        "X3 = cleaned_data[features_obj3]\n",
        "y3 = cleaned_data['Total Charges']\n",
        "\n",
        "# Encode categorical features\n",
        "X3['Payment Typology 1'] = encoder.fit_transform(X3['Payment Typology 1'])\n",
        "X3['CCS Procedure Code'] = cleaned_data['CCS Procedure Code'].fillna(0).astype(int)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X3_scaled = scaler.fit_transform(X3)\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_scaled, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X3_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))  # Output layer for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X3_train, y3_train, epochs=50, batch_size=32, verbose=1, validation_data=(X3_test, y3_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred = model.predict(X3_test)\n",
        "mse_obj3 = mean_squared_error(y3_test, y3_pred)\n",
        "mae_obj3 = mean_absolute_error(y3_test, y3_pred)\n",
        "r2_obj3 = r2_score(y3_test, y3_pred)\n",
        "\n",
        "print(f'Objective 3 - Mean Squared Error: {mse_obj3}')\n",
        "print(f'Objective 3 - Mean Absolute Error: {mae_obj3}')\n",
        "print(f'Objective 3 - R^2 Score: {r2_obj3}')\n",
        "\n",
        "# Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y3_test, y3_pred)\n",
        "plt.plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], '--', color='red')\n",
        "plt.xlabel('Actual Total Charges')\n",
        "plt.ylabel('Predicted Total Charges')\n",
        "plt.title('Actual vs Predicted Total Charges')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution\n",
        "errors = y3_test - y3_pred.flatten()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(errors, kde=True)\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.title('Distribution of Prediction Errors')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jebZFdOPt-46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dbn\n"
      ],
      "metadata": {
        "id": "rbE8np9hM1bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn-deep-belief-network\n"
      ],
      "metadata": {
        "id": "OqH4aQAFLnFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Adam optimizer Objective 2 - Accuracy: 0.9166666666666666\n",
        "\n",
        "*   Objective 2 - Precision: 1.0\n",
        "*   Objective 2 - Recall: 0.9\n",
        "*   Objective 2 - F1 Score: 0.9473684210526316\n",
        "*   Objective 2 - Confusion Matrix:\n",
        "[[2 0]\n",
        " [1 9]]\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       False       0.67      1.00      0.80         2\n",
        "        True       1.00      0.90      0.95        10\n",
        "\n",
        "    accuracy                           0.92        12\n",
        "   macro avg       0.83      0.95      0.87        12\n",
        "weighted avg       0.94      0.92      0.92        12\n"
      ],
      "metadata": {
        "id": "2EauSd_PaBG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 2\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X2_scaled = scaler.fit_transform(X2)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_scaled, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X2_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X2_train, y2_train, epochs=50, batch_size=32, verbose=1, validation_data=(X2_test, y2_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred = (model.predict(X2_test) > 0.5).astype(\"int32\")\n",
        "accuracy_obj2 = accuracy_score(y2_test, y2_pred)\n",
        "precision_obj2 = precision_score(y2_test, y2_pred)\n",
        "recall_obj2 = recall_score(y2_test, y2_pred)\n",
        "f1_obj2 = f1_score(y2_test, y2_pred)\n",
        "conf_matrix_obj2 = confusion_matrix(y2_test, y2_pred)\n",
        "\n",
        "print(f'Objective 2 - Accuracy: {accuracy_obj2}')\n",
        "print(f'Objective 2 - Precision: {precision_obj2}')\n",
        "print(f'Objective 2 - Recall: {recall_obj2}')\n",
        "print(f'Objective 2 - F1 Score: {f1_obj2}')\n",
        "print(f'Objective 2 - Confusion Matrix:\\n{conf_matrix_obj2}')\n",
        "print(classification_report(y2_test, y2_pred))\n"
      ],
      "metadata": {
        "id": "FIcoUN8CDBPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 2\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X2_scaled = scaler.fit_transform(X2)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_scaled, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X2_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X2_train, y2_train, epochs=50, batch_size=32, verbose=1, validation_data=(X2_test, y2_test))\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y2_pred_proba = model.predict(X2_test)\n",
        "y2_pred = (y2_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_obj2 = accuracy_score(y2_test, y2_pred)\n",
        "precision_obj2 = precision_score(y2_test, y2_pred)\n",
        "recall_obj2 = recall_score(y2_test, y2_pred)\n",
        "f1_obj2 = f1_score(y2_test, y2_pred)\n",
        "conf_matrix_obj2 = confusion_matrix(y2_test, y2_pred)\n",
        "\n",
        "print(f'Objective 2 - Accuracy: {accuracy_obj2}')\n",
        "print(f'Objective 2 - Precision: {precision_obj2}')\n",
        "print(f'Objective 2 - Recall: {recall_obj2}')\n",
        "print(f'Objective 2 - F1 Score: {f1_obj2}')\n",
        "print(f'Objective 2 - Confusion Matrix:\\n{conf_matrix_obj2}')\n",
        "print(classification_report(y2_test, y2_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_obj2, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y2_test, y2_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y2_test, y2_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy/Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UMKpc3EvDBMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Objective 3: Predicting Billing Amounts for Different Insurance Types\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 3\n",
        "features_obj3 = ['APR Severity of Illness Code', 'Payment Typology 1', 'CCS Procedure Code']\n",
        "X3 = cleaned_data[features_obj3]\n",
        "y3 = cleaned_data['Total Charges']\n",
        "\n",
        "# Encode categorical features\n",
        "X3['Payment Typology 1'] = encoder.fit_transform(X3['Payment Typology 1'])\n",
        "X3['CCS Procedure Code'] = cleaned_data['CCS Procedure Code'].fillna(0).astype(int)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X3_scaled = scaler.fit_transform(X3)\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_scaled, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X3_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))  # Output layer for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X3_train, y3_train, epochs=50, batch_size=32, verbose=1, validation_data=(X3_test, y3_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred = model.predict(X3_test)\n",
        "mse_obj3 = mean_squared_error(y3_test, y3_pred)\n",
        "mae_obj3 = mean_absolute_error(y3_test, y3_pred)\n",
        "r2_obj3 = r2_score(y3_test, y3_pred)\n",
        "\n",
        "print(f'Objective 3 - Mean Squared Error: {mse_obj3}')\n",
        "print(f'Objective 3 - Mean Absolute Error: {mae_obj3}')\n",
        "print(f'Objective 3 - R^2 Score: {r2_obj3}')\n",
        "\n",
        "# Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y3_test, y3_pred)\n",
        "plt.plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], '--', color='red')\n",
        "plt.xlabel('Actual Total Charges')\n",
        "plt.ylabel('Predicted Total Charges')\n",
        "plt.title('Actual vs Predicted Total Charges')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution\n",
        "errors = y3_test - y3_pred.flatten()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(errors, kde=True)\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.title('Distribution of Prediction Errors')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T4Eu9yXWDBKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing PCA to improve GBR performance"
      ],
      "metadata": {
        "id": "O5R_WYZMXgv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Features and target for Objective 3\n",
        "features_obj3 = ['APR Severity of Illness Code', 'Payment Typology 1', 'CCS Procedure Code']\n",
        "X3 = cleaned_data[features_obj3]\n",
        "y3 = cleaned_data['Total Charges']\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X3['Payment Typology 1'] = encoder.fit_transform(X3['Payment Typology 1'])\n",
        "X3['CCS Procedure Code'] = cleaned_data['CCS Procedure Code'].fillna(0).astype(int)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X3_scaled = scaler.fit_transform(X3)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
        "X3_pca = pca.fit_transform(X3_scaled)\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_pca, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train GBR model with PCA\n",
        "gbr_pca = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gbr_pca.fit(X3_train, y3_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred_pca = gbr_pca.predict(X3_test)\n",
        "mse_pca = mean_squared_error(y3_test, y3_pred_pca)\n",
        "mae_pca = mean_absolute_error(y3_test, y3_pred_pca)\n",
        "r2_pca = r2_score(y3_test, y3_pred_pca)\n",
        "\n",
        "print(f'PCA - Mean Squared Error: {mse_pca}')\n",
        "print(f'PCA - Mean Absolute Error: {mae_pca}')\n",
        "print(f'PCA - R^2 Score: {r2_pca}')\n",
        "\n",
        "# Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y3_test, y3_pred_pca)\n",
        "plt.plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], '--', color='red')\n",
        "plt.xlabel('Actual Total Charges')\n",
        "plt.ylabel('Predicted Total Charges')\n",
        "plt.title('Actual vs Predicted Total Charges (PCA)')\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution\n",
        "errors_pca = y3_test - y3_pred_pca\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(errors_pca, kde=True)\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.title('Distribution of Prediction Errors (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rBbzG_90XgDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing CFS to improve GBR model Performance"
      ],
      "metadata": {
        "id": "JzhgXQA2X1A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply CFS\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "X3_selected = selector.fit_transform(X3_scaled, y3)\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_selected, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train GBR model with CFS\n",
        "gbr_cfs = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gbr_cfs.fit(X3_train, y3_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred_cfs = gbr_cfs.predict(X3_test)\n",
        "mse_cfs = mean_squared_error(y3_test, y3_pred_cfs)\n",
        "mae_cfs = mean_absolute_error(y3_test, y3_pred_cfs)\n",
        "r2_cfs = r2_score(y3_test, y3_pred_cfs)\n",
        "\n",
        "print(f'CFS - Mean Squared Error: {mse_cfs}')\n",
        "print(f'CFS - Mean Absolute Error: {mae_cfs}')\n",
        "print(f'CFS - R^2 Score: {r2_cfs}')\n",
        "\n",
        "# Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y3_test, y3_pred_cfs)\n",
        "plt.plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], '--', color='red')\n",
        "plt.xlabel('Actual Total Charges')\n",
        "plt.ylabel('Predicted Total Charges')\n",
        "plt.title('Actual vs Predicted Total Charges (CFS)')\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution\n",
        "errors_cfs = y3_test - y3_pred_cfs\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(errors_cfs, kde=True)\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.title('Distribution of Prediction Errors (CFS)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a8YlwuwhX0R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing PCA to improve NN model Performance"
      ],
      "metadata": {
        "id": "myug_FSjY-vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 2\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X2_scaled = scaler.fit_transform(X2)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
        "X2_pca = pca.fit_transform(X2_scaled)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_pca, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X2_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_pca = model.fit(X2_train, y2_train, epochs=50, batch_size=32, verbose=1, validation_data=(X2_test, y2_test))\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y2_pred_proba_pca = model.predict(X2_test)\n",
        "y2_pred_pca = (y2_pred_proba_pca > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_pca = accuracy_score(y2_test, y2_pred_pca)\n",
        "precision_pca = precision_score(y2_test, y2_pred_pca)\n",
        "recall_pca = recall_score(y2_test, y2_pred_pca)\n",
        "f1_pca = f1_score(y2_test, y2_pred_pca)\n",
        "conf_matrix_pca = confusion_matrix(y2_test, y2_pred_pca)\n",
        "\n",
        "print(f'PCA - Accuracy: {accuracy_pca}')\n",
        "print(f'PCA - Precision: {precision_pca}')\n",
        "print(f'PCA - Recall: {recall_pca}')\n",
        "print(f'PCA - F1 Score: {f1_pca}')\n",
        "print(f'PCA - Confusion Matrix:\\n{conf_matrix_pca}')\n",
        "print(classification_report(y2_test, y2_pred_pca))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pca, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (PCA)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr_pca, tpr_pca, thresholds_pca = roc_curve(y2_test, y2_pred_proba_pca)\n",
        "roc_auc_pca = auc(fpr_pca, tpr_pca)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_pca, tpr_pca, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_pca:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (PCA)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_pca, recall_pca, _ = precision_recall_curve(y2_test, y2_pred_proba_pca)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_pca, precision_pca, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (PCA)')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history_pca.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_pca.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history_pca.history['loss'], label='Train Loss')\n",
        "plt.plot(history_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves (PCA)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy/Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G8AN1SV6YBUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing CFS to improve NN model Performance"
      ],
      "metadata": {
        "id": "RB7wK54OZbn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Apply CFS\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "X2_selected = selector.fit_transform(X2_scaled, y2)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_selected, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X2_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_cfs = model.fit(X2_train, y2_train, epochs=50, batch_size=32, verbose=1, validation_data=(X2_test, y2_test))\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y2_pred_proba_cfs = model.predict(X2_test)\n",
        "y2_pred_cfs = (y2_pred_proba_cfs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_cfs = accuracy_score(y2_test, y2_pred_cfs)\n",
        "precision_cfs = precision_score(y2_test, y2_pred_cfs)\n",
        "recall_cfs = recall_score(y2_test, y2_pred_cfs)\n",
        "f1_cfs = f1_score(y2_test, y2_pred_cfs)\n",
        "conf_matrix_cfs = confusion_matrix(y2_test, y2_pred_cfs)\n",
        "\n",
        "print(f'CFS - Accuracy: {accuracy_cfs}')\n",
        "print(f'CFS - Precision: {precision_cfs}')\n",
        "print(f'CFS - Recall: {recall_cfs}')\n",
        "print(f'CFS - F1 Score: {f1_cfs}')\n",
        "print(f'CFS - Confusion Matrix:\\n{conf_matrix_cfs}')\n",
        "print(classification_report(y2_test, y2_pred_cfs))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_cfs, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (CFS)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr_cfs, tpr_cfs, thresholds_cfs = roc_curve(y2_test, y2_pred_proba_cfs)\n",
        "roc_auc_cfs = auc(fpr_cfs, tpr_cfs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_cfs, tpr_cfs, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_cfs:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (CFS)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_cfs, recall_cfs, _ = precision_recall_curve(y2_test, y2_pred_proba_cfs)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_cfs, precision_pca, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (CFS)')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history_cfs.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_cfs.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history_cfs.history['loss'], label='Train Loss')\n",
        "plt.plot(history_cfs.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves (CFS)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy/Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EC1BDzwfZbAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing PCA to improve RFR model Performance"
      ],
      "metadata": {
        "id": "Fr5vbmoKbx-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 2\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X2_scaled = scaler.fit_transform(X2)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
        "X2_pca = pca.fit_transform(X2_scaled)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_pca, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_pca.fit(X2_train, y2_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred_pca = rf_classifier_pca.predict(X2_test)\n",
        "accuracy_pca = accuracy_score(y2_test, y2_pred_pca)\n",
        "precision_pca = precision_score(y2_test, y2_pred_pca)\n",
        "recall_pca = recall_score(y2_test, y2_pred_pca)\n",
        "f1_pca = f1_score(y2_test, y2_pred_pca)\n",
        "conf_matrix_pca = confusion_matrix(y2_test, y2_pred_pca)\n",
        "\n",
        "print(f'PCA - Accuracy: {accuracy_pca}')\n",
        "print(f'PCA - Precision: {precision_pca}')\n",
        "print(f'PCA - Recall: {recall_pca}')\n",
        "print(f'PCA - F1 Score: {f1_pca}')\n",
        "print(f'PCA - Confusion Matrix:\\n{conf_matrix_pca}')\n",
        "print(classification_report(y2_test, y2_pred_pca))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pca, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (PCA)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y2_pred_proba_pca = rf_classifier_pca.predict_proba(X2_test)[:, 1]\n",
        "fpr_pca, tpr_pca, thresholds_pca = roc_curve(y2_test, y2_pred_proba_pca)\n",
        "roc_auc_pca = auc(fpr_pca, tpr_pca)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_pca, tpr_pca, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_pca:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (PCA)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_pca, recall_pca, _ = precision_recall_curve(y2_test, y2_pred_proba_pca)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_pca, precision_pca, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1sfUaw7xbxZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing CFS to improve rfc model Performance"
      ],
      "metadata": {
        "id": "2mDyPkXBbyh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Apply CFS\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "X2_selected = selector.fit_transform(X2_scaled, y2)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_selected, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier_cfs = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_cfs.fit(X2_train, y2_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred_cfs = rf_classifier_cfs.predict(X2_test)\n",
        "accuracy_cfs = accuracy_score(y2_test, y2_pred_cfs)\n",
        "precision_cfs = precision_score(y2_test, y2_pred_cfs)\n",
        "recall_cfs = recall_score(y2_test, y2_pred_cfs)\n",
        "f1_cfs = f1_score(y2_test, y2_pred_cfs)\n",
        "conf_matrix_cfs = confusion_matrix(y2_test, y2_pred_cfs)\n",
        "\n",
        "print(f'CFS - Accuracy: {accuracy_cfs}')\n",
        "print(f'CFS - Precision: {precision_cfs}')\n",
        "print(f'CFS - Recall: {recall_cfs}')\n",
        "print(f'CFS - F1 Score: {f1_cfs}')\n",
        "print(f'CFS - Confusion Matrix:\\n{conf_matrix_cfs}')\n",
        "print(classification_report(y2_test, y2_pred_cfs))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_cfs, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (CFS)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y2_pred_proba_cfs = rf_classifier_cfs.predict_proba(X2_test)[:, 1]\n",
        "fpr_cfs, tpr_cfs, thresholds_cfs = roc_curve(y2_test, y2_pred_proba_cfs)\n",
        "roc_auc_cfs = auc(fpr_cfs, tpr_cfs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_cfs, tpr_cfs, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_cfs:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (CFS)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_cfs, recall_cfs, _ = precision_recall_curve(y2_test, y2_pred_proba_cfs)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_cfs, precision_cfs, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (CFS)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wLq0_Tf8beEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying PCA for Objective 2 with Random Forest Classifier"
      ],
      "metadata": {
        "id": "yeXPNjcZcU1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Create Billing Discrepancy column\n",
        "cleaned_data['Billing Discrepancy'] = cleaned_data['Total Charges'] - cleaned_data['Total Costs']\n",
        "\n",
        "# Features and target for Objective 2\n",
        "features_obj2 = ['APR Severity of Illness Code', 'Total Charges', 'Total Costs', 'Payment Typology 1']\n",
        "X2 = cleaned_data[features_obj2]\n",
        "y2 = cleaned_data['Billing Discrepancy'] > 100  # Example threshold for billing error\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "X2['Payment Typology 1'] = encoder.fit_transform(X2['Payment Typology 1'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X2_scaled = scaler.fit_transform(X2)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
        "X2_pca = pca.fit_transform(X2_scaled)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_pca, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_pca.fit(X2_train, y2_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred_pca = rf_classifier_pca.predict(X2_test)\n",
        "accuracy_pca = accuracy_score(y2_test, y2_pred_pca)\n",
        "precision_pca = precision_score(y2_test, y2_pred_pca)\n",
        "recall_pca = recall_score(y2_test, y2_pred_pca)\n",
        "f1_pca = f1_score(y2_test, y2_pred_pca)\n",
        "conf_matrix_pca = confusion_matrix(y2_test, y2_pred_pca)\n",
        "\n",
        "print(f'PCA - Accuracy: {accuracy_pca}')\n",
        "print(f'PCA - Precision: {precision_pca}')\n",
        "print(f'PCA - Recall: {recall_pca}')\n",
        "print(f'PCA - F1 Score: {f1_pca}')\n",
        "print(f'PCA - Confusion Matrix:\\n{conf_matrix_pca}')\n",
        "print(classification_report(y2_test, y2_pred_pca))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pca, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (PCA)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y2_pred_proba_pca = rf_classifier_pca.predict_proba(X2_test)[:, 1]\n",
        "fpr_pca, tpr_pca, thresholds_pca = roc_curve(y2_test, y2_pred_proba_pca)\n",
        "roc_auc_pca = auc(fpr_pca, tpr_pca)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_pca, tpr_pca, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_pca:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (PCA)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_pca, recall_pca, _ = precision_recall_curve(y2_test, y2_pred_proba_pca)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_pca, precision_pca, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5VGwQ5z1cV4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying CFS for Objective 2 with Random Forest Classifier"
      ],
      "metadata": {
        "id": "_9aH5LMjcXae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Apply CFS\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "X2_selected = selector.fit_transform(X2_scaled, y2)\n",
        "\n",
        "# Split data\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_selected, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier_cfs = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_cfs.fit(X2_train, y2_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y2_pred_cfs = rf_classifier_cfs.predict(X2_test)\n",
        "accuracy_cfs = accuracy_score(y2_test, y2_pred_cfs)\n",
        "precision_cfs = precision_score(y2_test, y2_pred_cfs)\n",
        "recall_cfs = recall_score(y2_test, y2_pred_cfs)\n",
        "f1_cfs = f1_score(y2_test, y2_pred_cfs)\n",
        "conf_matrix_cfs = confusion_matrix(y2_test, y2_pred_cfs)\n",
        "\n",
        "print(f'CFS - Accuracy: {accuracy_cfs}')\n",
        "print(f'CFS - Precision: {precision_cfs}')\n",
        "print(f'CFS - Recall: {recall_cfs}')\n",
        "print(f'CFS - F1 Score: {f1_cfs}')\n",
        "print(f'CFS - Confusion Matrix:\\n{conf_matrix_cfs}')\n",
        "print(classification_report(y2_test, y2_pred_cfs))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_cfs, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (CFS)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y2_pred_proba_cfs = rf_classifier_cfs.predict_proba(X2_test)[:, 1]\n",
        "fpr_cfs, tpr_cfs, thresholds_cfs = roc_curve(y2_test, y2_pred_proba_cfs)\n",
        "roc_auc_cfs = auc(fpr_cfs, tpr_cfs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_cfs, tpr_cfs, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_cfs:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve (CFS)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_cfs, recall_cfs, _ = precision_recall_curve(y2_test, y2_pred_proba_cfs)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_cfs, precision_cfs, lw=2, color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (CFS)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TNgzhdN5cWbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logistic regression"
      ],
      "metadata": {
        "id": "tNqqk7pCcWMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2017_20240120 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "data['Length of Stay'] = pd.to_numeric(data['Length of Stay'], errors='coerce')\n",
        "data['Total Charges'] = pd.to_numeric(data['Total Charges'], errors='coerce')\n",
        "data['Total Costs'] = pd.to_numeric(data['Total Costs'], errors='coerce')\n",
        "cleaned_data = data.dropna(subset=['Length of Stay', 'Total Charges', 'Total Costs'])\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Features and target for Objective 3\n",
        "features_obj3 = ['APR Severity of Illness Code', 'Payment Typology 1', 'CCS Procedure Code']\n",
        "X3 = cleaned_data[features_obj3]\n",
        "y3 = cleaned_data['Total Charges']\n",
        "\n",
        "# Encode categorical features\n",
        "X3['Payment Typology 1'] = encoder.fit_transform(X3['Payment Typology 1'])\n",
        "X3['CCS Procedure Code'] = cleaned_data['CCS Procedure Code'].fillna(0).astype(int)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X3_scaled = scaler.fit_transform(X3)\n",
        "\n",
        "# Split data\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_scaled, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression model\n",
        "linear_regressor = LinearRegression()\n",
        "linear_regressor.fit(X3_train, y3_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y3_pred = linear_regressor.predict(X3_test)\n",
        "mse = mean_squared_error(y3_test, y3_pred)\n",
        "mae = mean_absolute_error(y3_test, y3_pred)\n",
        "r2 = r2_score(y3_test, y3_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'R Score: {r2}')\n",
        "\n",
        "# Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y3_test, y3_pred)\n",
        "plt.plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], '--', color='red')\n",
        "plt.xlabel('Actual Total Charges')\n",
        "plt.ylabel('Predicted Total Charges')\n",
        "plt.title('Actual vs Predicted Total Charges')\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution\n",
        "errors = y3_test - y3_pred\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(errors, kde=True)\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.title('Distribution of Prediction Errors')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R-nzUbGfBuCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}